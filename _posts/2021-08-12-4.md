---
layout: post
title:  "[15-1] kNN 알고리즘"
summary: 
author: hipass7
date: '2021-08-11 22:00:00 +0900'
category: openCV
thumbnail: /assets/img/4/1.png
permalink: /blog/4/
---

# [15-1] kNN 알고리즘

- KNearest 클래스 사용하기
- `program knn plane`

### 도입

kNN 알고리즘은 가장 기본적으로 2차원 평면에 분포하는 점들을 분류할 때 사용된다. 특정 공간에서 테스트 데이터와 가장 가까운 k개의 훈련 데이터를 찾아 가장 많은 클래스를 테스트 데이터의 클래스로 지정한다. <br />
이 알고리즘을 사용하기 위해 우선 KNearest 클래스의 기본적인 함수를 살펴보고 직접 예제를 실행해볼 예정이다.


**1.**

```c++
static Ptr<KNearest> KNearest::creatre();
```

- 반환값 : KNearest 객체를 참조하는 Ptr 스마트 포인터 객체

이 함수는 클래스를 이용하기 위해 객체를 생성하는 함수로 포인터 객체로 반환된다는 점이 중요하다. 기본적으로 k값을 10으로 설정한다. 이 값을 변경하는 함수를 살펴보자.

**2.**

```c++
virtual void KNearest::setDefaultK(int val);
```

- val : kNN 알고리즘에서 사용할 k값

이 함수는 몇 개의 훈련 데이터를 참고할지 k값을 정할 수 있는 함수이다.

**3.**

```c++
virtual void KNearest::setIsClassifier(bool val);
```

- val : true이면 분류, false이면 회귀로 사용한다.

이 함수는 kNN 알고리즘을 사용할 방법을 정하는 함수이다. 속성을 분류로 설정하면 소속된 항목이 출력되고, 회귀로 설정하면 객체의 특성값이 출력된다. 보통 분류를 위한 용도로 생성되기때문에 잘 사용하지 않는다.

**4.**

```c++
virtual float KNearest::findNearest(InputArray samples, int k, OutputArray results, OutputArray neightborResponses = noArray(), OutputArray dist = noArray()) const;
```

- samples : 테스트 데이터 벡터가 행 단위로 저장된 행렬이며 입력 벡터의 차원은 훈련 벡터의 차원과 같아야하며, 행렬 타입은 CV_32FC1이어야 한다.
- k : 사용할 최근접 이웃 개수로 반드시 1 이상이어야 한다.
- results : 각 입력 샘플에 대한 예측 결과를 저장한 행렬이며 samples.row x 1 크기를 갖는다.
- neighborResponses : 예측에 사용된 k개의 최근접 이웃 클래스 정보를 담고 있는 행렬이며 samples.rows x k 크기를 갖는다.
- dist : 입력 벡터와 예측에 사용된 k개의 최근접 이웃과의 거리를 저장한 행렬이며 samples.rows x k 크기를 갖는다.
- 반환값 : 입력 벡터가 하나인 경우에 대한 응답이 반환된다.

아래는 kNN 알고리즘에 대한 기초 예제이며 필요한 설명은 주석으로 대체하였다. <br /> <br />
## 예제

```c++
#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace cv::ml;
using namespace std;

Mat img;
Mat train, label;
Ptr<KNearest> knn;
int k_value = 1;

void on_k_changed(int, void*);
void addPoint(const Point& pt, int cls);
void trainAndDisplay();

int main(){
    img = Mat::zeros(Size(1000, 1000), CV_8UC3); // 해당 크기의 빈 객체 생성
    knn = KNearest::create(); // kNearest 클래스를 갖는 객체 생성 (포인터)
    
    namedWindow("knn");
    createTrackbar("k", "knn", &k_value, 10, on_k_changed);
    
    const int NUM = 100;
    Mat rn(NUM, 2, CV_32SC1); // 100 x 2 행렬 생성
    
    randn(rn, 0, 100); // 표준편차 100 범위 내에서 랜덤
    for (int i = 0; i < NUM; i++){
        addPoint(Point(rn.at<int>(i, 0) + 300, rn.at<int>(i, 1) + 300), 0);
    } // 랜덤으로 생성된 데이터를 지정하여 train과 label객체에 삽입
    
    randn(rn, 0, 100);
    for (int i = 0; i < NUM; i++){
        addPoint(Point(rn.at<int>(i, 0) + 700, rn.at<int>(i, 1) + 300), 1);
    }
            
    randn(rn, 0, 150);
    for (int i = 0; i < NUM; i++){
        addPoint(Point(rn.at<int>(i, 0) + 500, rn.at<int>(i, 1) + 800), 2);
    }
    
    trainAndDisplay();
    
    waitKey();
    return 0;
}

void on_k_changed(int, void*){
    if (k_value < 1) k_value = 1;
    trainAndDisplay();
}

void addPoint(const Point& pt, int cls){
    Mat new_sample = (Mat_<float>(1, 2) << pt.x, pt.y);
    train.push_back(new_sample);
    // Mat_ 객체는 객체에 요소 할당이 편리하기에 사용함 ( << )
    // float로 이루어진 1 x 2 행렬에 pt.x와 pt.y값을 할당하여 새로운 Mat 객체에 할당
    
    Mat new_label = (Mat_<int>(1, 1) << cls);
    label.push_back(new_label);
}

void trainAndDisplay(){
    knn->train(train, 0, label); // knn은 포인터라는 것을 명심
    // 0은 타입으로 ROW_SAMPLE과 동일
    
    for (int i = 0; i < img.rows; ++i){
        for (int j = 0; j < img.cols; ++j){
            Mat sample = (Mat_<float>(1, 2) << j, i);
            
            Mat res;
            knn->findNearest(sample, k_value, res);
            // sample에 등록된 픽셀에서 k값에 따라 나오는 res값을 반올림하여 int로 할당
            
            int response = cvRound(res.at<float>(0,0));
            if(response == 0)
                img.at<Vec3b>(i, j) = Vec3b(128, 128, 255);
            else if (response == 1)
                img.at<Vec3b>(i, j) = Vec3b(128, 255, 128);
            else if (response == 2)
                img.at<Vec3b>(i, j) = Vec3b(255, 128, 128);
            // response값에 따라 이곳이 어떤 클래스에 속하는게 맞는지 구분을 한다.
        }
    }
    
    for (int i = 0; i < train.rows; i++){
        int x = cvRound(train.at<float>(i, 0));
        int y = cvRound(train.at<float>(i, 1));
        int l = label.at<int>(i, 0);
        
        if (l == 0)
            circle(img, Point(x, y), 5, Scalar(0, 0, 128), -1, LINE_AA);
        else if (l == 1)
            circle(img, Point(x, y), 5, Scalar(0, 128, 0), -1, LINE_AA);
        else if (l == 2)
            circle(img, Point(x, y), 5, Scalar(128, 0, 0), -1, LINE_AA);
        // 이 for문은 훈련된 데이터의 지점을 표시해주는 알고리즘이다.
        // LINE_AA는 커브를 위해 ANTI-ALIASING이 적용된 선의 속성이다.
    }
    imshow("knn", img);
}


```
결과를 살펴보자.

**# k = 1일 때**

![png](/assets/img/4/1.png)

**# k = 2일 때**

![png](/assets/img/4/2.png)

**# k = 3일 때**

![png](/assets/img/4/3.png)

**# k = 4일 때**

![png](/assets/img/4/4.png)

**# k = 5일 때**

![png](/assets/img/4/5.png)

**# k = 6일 때**

![png](/assets/img/4/6.png)

------
사진에서 확인할 수 있듯이 kNN 알고리즘에서 k의 수가 커질수록 조금 더 자연스러운 영역 분배가 이루어지는 것을 확인할 수 있다. <br /><br />
앞서 말한것처럼 이 알고리즘은 k값이 증가함에 따라 잡음 또는 이상치에 해당하는 훈련 데이터 영향이 줄어드는 것을 보여준다. <br />