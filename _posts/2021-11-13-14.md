---
layout: post
title:  "[2021 KHUTHON] 좋은 말 고운 말"
summary: 
author: hipass7
date: '2021-11-13 21:00:00 +0900'
category: python
thumbnail: /assets/img/14/2.jpg
permalink: /blog/14/
---

# [2021 KHUTHON] 좋은 말 고운 말

- 2021 KHUTHON (경희대 해커톤)
- AI로 극복하는 재난

### 도입

2021년 11월 12일부터 13일까지 무박 2일동안 경희대학교 중앙동아리 KHLUG에서 주최하는 KHUTHON에 참가한 프로젝트 결과물입니다. 이번 글에서는 발표 형식으로 이번 결과물을 소개할 예정입니다.

**재난?**

주제가 AI로 극복하는 재난이라고 주어졌을 때, 모든 분야에서의 AI 접목은 어렵지 않을 것이라고 판단되어 재난에 대해 먼저 생각해보았습니다. 현재 코로나19 팬데믹 상황을 겪고 있는 만큼 위드코로나를 위한 프로그램에 대해 생각해보고 싶었으나, 독창성이 떨어질 것을 염려하여 산불, 교통사고 등 다른 재난을 생각하다가 아주 세부적인 재난에 대해서 다루기로 하였습니다. 그것은 바로 자살이었습니다.

**자살률 증가**

뉴스에서 우리나라 자살률이 증가했다는 멘트를 자주 볼 수 있었습니다. 이 자살률 증가 원인 중 하나로 우울증을 꼽았고, 이 우울증은 인간 관계에서 서로 간의 상처로 인해 발생한다고 생각했습니다. 따라서 서로 상처줄 수 있는 말들을 교정해줄 수 있는 AI 프로그램에 대해 생각해보기로 했습니다.

**실시간 음성 욕설 인식**

Google Cloud Speech API를 사용해서 음성 파일을 텍스트로 변환하는 작업을 하였습니다. 이후 음성 파일이 아닌 마이크로 실시간 스트리밍하는 레퍼런스도 참고하여 만들 수 있었습니다. 텍스트 파일로 욕설 단어 데이터를 불러와서 해당 되는 단어가 들어가있는 부분을 캐치하여 어떤 욕설을 몇 회 하였는지 기록하게 됩니다.

**데이터베이스 및 웹 구축**

다음 사진과 같이 AWS와 MariaDB 등을 이용하여 홈페이지를 구성하였고 회원가입, 로그인 기능도 데이터베이스를 통해 구현했습니다. 이후 버튼을 누르면 기록을 시작하도록, 종료하도록 기능을 구현하였고 결과적으로 자신이 어떤 단어의 욕설을 몇 회 하였는지 출력을 할 수 있게 됩니다. 사용한 데이터베이스 정보는 아래 사진을 참고하시기 바랍니다. (담당팀원 : happysms)

![png](/assets/img/14/3.PNG){: width="50%"}
![png](/assets/img/14/4.PNG){: width="50%"}

**코드 구현**

저는 이 프로젝트에서 사용자의 음성 입력을 스트리밍으로 받아 텍스트로 변환한 뒤, 욕설을 필터링하여 그 단어와 횟수를 기록하는 역할을 하였습니다. 전반적인 python 코드 구현을 맡았으며 Google Cloud Speech API를 이용한 코드입니다. 자세한 부분은 github에서 확인할 수 있습니다. API를 이용하기 때문에 반드시 API 권한 설정은 따로 하셔야합니다.
(https://github.com/hipass7/2021khuthon)

```python
from __future__ import division

import re
import sys

from google.cloud import speech

import pyaudio
from six.moves import queue

import requests
import json

RATE = 44100
CHUNK = int(RATE / 10)

words = []

class MicrophoneStream(object):
    def __init__(self, rate, chunk):
        self._rate = rate
        self._chunk = chunk

        self._buff = queue.Queue()
        self.closed = True

    def __enter__(self):
        self._audio_interface = pyaudio.PyAudio()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self._rate,
            input=True,
            frames_per_buffer=self._chunk,
            stream_callback=self._fill_buffer,
        )

        self.closed = False

        return self

    def __exit__(self, type, value, traceback):
        self._audio_stream.stop_stream()
        self._audio_stream.close()
        self.closed = True
        self._buff.put(None)
        self._audio_interface.terminate()

    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):
        self._buff.put(in_data)
        return None, pyaudio.paContinue

    def generator(self):
        while not self.closed:
            chunk = self._buff.get()
            if chunk is None:
                return
            data = [chunk]

            while True:
                try:
                    chunk = self._buff.get(block=False)
                    if chunk is None:
                        return
                    data.append(chunk)
                except queue.Empty:
                    break

            yield b"".join(data)

def listen_print_loop(responses):
    num_chars_printed = 0
    for response in responses:
        if not response.results:
            num_chars_printed = 0
            continue

        res = requests.get("http://localhost:8000/accounts/check/")
        check = json.loads(res.text)
        if check['check'] == False:
            break

        result = response.results[0]
        if not result.alternatives:
            continue

        transcript = result.alternatives[0].transcript

        overwrite_chars = " " * (num_chars_printed - len(transcript))

        if not result.is_final:
            sys.stdout.write(transcript + overwrite_chars + "\r")
            sys.stdout.flush()

            num_chars_printed = len(transcript)

        else:
            print(transcript + overwrite_chars)

            line = transcript + overwrite_chars
            line = line.split(' ')
            words.append(line)

            if re.search(r"\b(exit|quit)\b", transcript, re.I):
                print("Exiting..")
                break

            num_chars_printed = 0


def main():
    language_code = "ko-KR"

    client = speech.SpeechClient()
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code=language_code,
    )

    streaming_config = speech.StreamingRecognitionConfig(
        config=config, interim_results=True
    )

    with MicrophoneStream(RATE, CHUNK) as stream:
        audio_generator = stream.generator()
        requests = (
            speech.StreamingRecognizeRequest(audio_content=content)
            for content in audio_generator
        )

        responses = client.streaming_recognize(streaming_config, requests)
        
        listen_print_loop(responses)
        

if __name__ == "__main__":
    res = requests.get("http://localhost:8000/accounts/check/")
    check = json.loads(res.text)
    while not check['check']:
        res = requests.get("http://localhost:8000/accounts/check/")
        check = json.loads(res.text)
        
    while check['check']:
        main()
        res = requests.get("http://localhost:8000/accounts/check/")
        check = json.loads(res.text)

    result = sum(words, [])
    print(result)

    yok = []
    f = open('TEST.txt','r',encoding='utf-8') # txt파일은 욕설 단어 종류가 담긴 데이터 오픈소스
    for line in f:
        line = line.split(',')
    
    for i in line:
        if i in result:
            yok.append(
                i
            )

    print(yok)
    print(len(yok), "번 욕을 하셨습니다.")

```

아래는 직접 시연하는 것을 촬영한 영상입니다. 다음과 같이 서버를 열어 홈페이지를 실행시키고 녹음 시작 버튼을 누르게 되면, 사용자의 음성을 스트리밍으로 받아 텍스트로 바로 변환하면서 이 텍스트에 있는 욕설과 그 횟수를 기록하여 터미널과 홈페이지에 출력하는 것을 알 수 있습니다. 예시 시연이기 때문에 참고만 하시기 바랍니다.

<iframe width="560" height="315" src="https://www.youtube.com/embed/GWqugxQZaco" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

**개선 필요 사항**

무박 2일동안 작업한 사항이라 프로그램이 완벽하게 구현되지는 않았습니다. 유저가 사용하기 전에 직접 녹음 시작 버튼을 눌러줘야 하는 점과 임시로 서버를 구축했기 때문에 서버 호출량이 많아 음성 인식이 딜레이가 되는 상황입니다. 따라서, 대형 서버를 구축하거나 스트리밍은 지속하면서 서버 호출량을 줄일 수 있는 방법을 고안해야합니다. 또한, 시중에 있는 자동 녹화 시스템처럼 자동으로 녹음이 진행될 수 있도록 다른 어플과의 연동이 필요합니다.

**기대 효과**

요즘엔 게임이나 코로나19 팬데믹으로 인해 화상 채팅을 사용하기 위해 음성을 사용하는 경우가 많습니다. 이 말에 잘못된 단어가 섞여있다는 것을 말을 할 당시에는 모르지만 나중에 통계적으로 결과가 나온다면 그에 대한 심각성을 분명히 인지할 수 있을 것입니다. 따라서, 음성을 사용하는 어플(Discord, Zoom 등)에 이러한 서비스를 추가한다면 바른 언어를 사용하는 문화로 한 걸음 더 나아갈 수 있을 것으로 기대됩니다.

![png](/assets/img/14/1.jpg){: width="50%"}